{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jalynmb/TermProjectNLP/blob/main/TermProjectNLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZFy7jeM3Agh"
      },
      "outputs": [],
      "source": [
        "!pip install pandas\n",
        "!pip install --upgrade tensorflow\n",
        "!pip install --upgrade scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2 align=\"center\">Sentiment Analysis <h2>\n",
        "<h3 align = \"center\">Natural Language Processing<h3>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uD2lUNzT3hHn"
      },
      "outputs": [],
      "source": [
        "#Import required Libraries\n",
        "import pandas as pd\n",
        "\n",
        "#Libraies to clean the data\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "#library for data Visualization\n",
        "import wordcloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#library and function for tokanization and vectorization\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#Importing libraries to build our models\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3 align = \"center\"> 1. Corpus <h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJEt8s6p5qEP",
        "outputId": "33a07c57-83d0-425f-f9f9-85de29d42cf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   rating       date         variation  \\\n",
            "0       5  31-Jul-18  Charcoal Fabric    \n",
            "1       5  31-Jul-18  Charcoal Fabric    \n",
            "2       4  31-Jul-18    Walnut Finish    \n",
            "3       5  31-Jul-18  Charcoal Fabric    \n",
            "4       5  31-Jul-18  Charcoal Fabric    \n",
            "\n",
            "                                    verified_reviews  feedback  \n",
            "0                                      Love my Echo!         1  \n",
            "1                                          Loved it!         1  \n",
            "2  Sometimes while playing a game, you can answer...         1  \n",
            "3  I have had a lot of fun with this thing. My 4 ...         1  \n",
            "4                                              Music         1  \n"
          ]
        }
      ],
      "source": [
        "file_path = 'dataset/customer_reviewers.tsv'\n",
        "data = pd.read_csv(file_path, delimiter= '\\t')\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Printing the first 5 reviews of our dataset\n",
        "for review in data['verified_reviews'].iloc[0:5]:\n",
        "    print(\"\\n\",review)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h3 align = \"center\">2. Cleaning and Segmentation<h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "data['verified_reviews'] = data['verified_reviews'].apply(lambda word:' '.join(word.lower() for word in str(word).split()))\n",
        "\n",
        "data['verified_reviews'] = data['verified_reviews'].str.replace('\\\\d+',' ',regex=True)\n",
        "\n",
        "data['verified_reviews'] = data['verified_reviews'].str.replace('\\\\W',' ',regex=True)\n",
        "\n",
        "print(data.head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Remove StopWords: To remove stopword you use the Library nltk, in particular you will need to import nltk.corpus.\n",
        "\n",
        "stopwords_list = set(stopwords.words('english'))\n",
        "data['verified_reviews'] = data['verified_reviews'].apply(lambda word: ' '.join([word for word in word.split() if word not in stopwords_list]))\n",
        "\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Printing the first 5 news of our dataset\n",
        "for review in data['verified_reviews'].iloc[0:5]:\n",
        "    print(\"\\n\",review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\FAMU.DESKTOP-QGE575J\\TermProjectNLP\\TermProjectNLP.ipynb Cell 12\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/FAMU.DESKTOP-QGE575J/TermProjectNLP/TermProjectNLP.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#Create a cloud of words upon their frequency: We will use two libraries wordcloud and matplotlib.\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/FAMU.DESKTOP-QGE575J/TermProjectNLP/TermProjectNLP.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m common_words\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/FAMU.DESKTOP-QGE575J/TermProjectNLP/TermProjectNLP.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mverified_reviews:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/FAMU.DESKTOP-QGE575J/TermProjectNLP/TermProjectNLP.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     i \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(i)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/FAMU.DESKTOP-QGE575J/TermProjectNLP/TermProjectNLP.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     word \u001b[39m=\u001b[39m i\u001b[39m.\u001b[39msplit()\n",
            "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ],
      "source": [
        "#Create a cloud of words upon their frequency: We will use two libraries wordcloud and matplotlib.\n",
        "\n",
        "common_words=''\n",
        "\n",
        "for i in data.verified_reviews:\n",
        "    i = str(i)\n",
        "    word = i.split()\n",
        "    common_words += \" \".join(word)+\" \"\n",
        "print(common_words)   \n",
        "\n",
        "\n",
        "wordcloud = wordcloud.WordCloud(width = 800, height = 800, background_color='white', min_font_size=10, collocations=False).generate(common_words)\n",
        "\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMxDm3mzfIJNCejOpoxaOSy",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
